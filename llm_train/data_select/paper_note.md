

***

# title: Boosting LLM via Learning from Data Iteratively and Selectively

##	背景: 
训练数据的复杂度+多样性
##	动机:
##	核心工作：
复杂度: 加指令ppl/不加指令ppl； 多样性：tf-idf； 数量？ 
##	相关工作：
##	核心方法:
##	基线：
1. vanilla
2. longest
3. deita
4. superfiltering
5. graphfilter
##	数据集：
##	效果:
##	消融实验:
##	结论:

___

# title: What Makes Good Data for Alignment? A Comprehensive Study of Automatic Data Selection in Instruction Tuning
##	背景: 
ift 阶段 ，数据工程很重要，如果选择合适，只需要少量数据就行。 但是我们仍然缺乏对数据自动选择的有效理解。 本文从数据 复杂度、多样性、数量三个维度理解数据，提出deita，用更少的数据执行更好。(10分之一
##	动机:
##	核心工作：
##	相关工作：
##	核心方法:
##	基线：
##	数据集：
##	效果:
##	消融实验:
##	结论: